Python 数据分析入门三时间序列处理
内容简介
本实验主要谈论数据分析过程中的时间序列分析。会涉及到 Pandas 针对时间序列分析处理的一些方法。

知识点

时间序列基础知识
时间戳和时间戳索引
DateOffset 对象
Period 时间间隔
时序数据检索
时序数据偏移
时序数据重采样
时间序列简介

时间序列分析是数据分析过程中，尤其是在金融数据分析过程中会经常遇到的。时间序列，就是以时间排序的一组随机变量，例如国家统计局每年或每月定期发布的 GDP 或 CPI 指数；24 小时内某一股票、基金、指数的数值变化等，都是时间序列。

下图截取自雅虎财经网站，它就是纳斯达克指数某一天内数值变化（时间序列）的可视化结果。



时间序列处理

当我们拿到一些时间序列原始数据时，可能会遇到下面的一些情况：

某一段时间缺失，需要填充。
时间序列错位，需要对齐。
数据表 a 和数据表 b 所采用的时间间隔不一致，需要重新采样。

……

面对这些问题，我们就要通过一些处理手段来获得最终想要的数据。本节课程中，我们会继续用到 Pandas 提供的时间序列处理模块，下面先看一些基本的方法和操作。

目前，Pandas 针对时间序列处理的类和方法如下：



我们按照顺序来看一看这些方法可以做什么。

Timestamp 时间戳

时间戳，即代表一个时间时刻。我们可以直接用 pd.Timestamp()来创建时间戳。我们使用 ipython 演示，在重点中通过 anaconda3/bin/ipython 打开。（小提示：使用 ipython 时，可以通过 Tab 键完成代码自动补全。）

In [1]: import pandas as pd

In [2]: pd.Timestamp("2017-1-1")
Out[2]: Timestamp('2017-01-01 00:00:00')

In [3]: pd.Timestamp(2017,10,1)
Out[3]: Timestamp('2017-10-01 00:00:00')

In [4]: pd.Timestamp("2017-1-1 12:59:59")
Out[4]: Timestamp('2017-01-01 12:59:59')
时间戳索引

我们可以看到，单个时间戳为 Timestamp 数据，而时间戳以列表形式存在时，Pandas 将强制转换为 DatetimeIndex。此时，我们就不能再使用 pd.Timestamp()来创建时间戳了，而是 pd.to_datetime()来创建：

In [6]: pd.to_datetime(["2017-1-1","2017-1-2","2017-1-3"])
Out[6]: DatetimeIndex(['2017-01-01', '2017-01-02', '2017-01-03'], dtype='datetime64[ns]', freq=None)
注意输出部分和上面的区别。

pd.to_datetime() 不仅仅可用来创建 DatetimeIndex，它还可以将对时间戳序列格式进行转换等操作。例如下面，常见的时间戳书写样式，都可以通过pd.to_datetime() 规范化。

In [7]: pd.to_datetime(['Jul 1, 2017', '2017-10-10', None])
Out[7]: DatetimeIndex(['2017-07-01', '2017-10-10', 'NaT'], dtype='datetime64[ns]', freq=None)

In [8]: pd.to_datetime(['2017/10/1', '2017.1.31'])
Out[8]: DatetimeIndex(['2017-10-01', '2017-01-31'], dtype='datetime64[ns]', freq=None)
对于欧洲时区普遍采用的书写样式，我们还可以通过 dayfirst=True 参数进行修正：


In [11]: pd.to_datetime('1-10-2017')
Out[11]: Timestamp('2017-01-10 00:00:00')

In [12]: pd.to_datetime('1-10-2017', dayfirst=True)
Out[12]: Timestamp('2017-10-01 00:00:00')
当然，Pandas 所熟悉的 Seris 和 DataFrame 格式的字符串，往往可以直接转换为 DatetimeIndex：


In [15]: pd.to_datetime(pd.Series(['2017-1-1', '2017-1-2', '2017-1-3']))
Out[15]:
0   2017-01-01
1   2017-01-02
2   2017-01-03
dtype: datetime64[ns]

In [16]: pd.to_datetime(pd.DataFrame({'year': [2017, 2017], 'month': [1, 2], 'day': [3, 4], 'hour': [5, 6]}))
Out[16]:
0   2017-01-03 05:00:00
1   2017-02-04 06:00:00
dtype: datetime64[ns]
如果要转换如上所示的DataFrame，必须存在的列名有year，month，day。另外 hour, minute, second, millisecond, microsecond, nanosecond可选。

当我们在使用pd.to_datetime() 转换数据时，很容易遇到无效数据。有一些任务对无效数据非常苛刻，所以报错让我们找到这些无效数据是不错的方法。当然，也有一些任务不在乎零星的无效数据，这时候就可以选择忽略。

# 遇到无效数据报错
In [17]: pd.to_datetime(['2017-1-1', 'invalid'], errors='raise')
ValueError: Unknown string format

# 忽略无效数据
In [18]: pd.to_datetime(['2017-1-1', 'invalid'], errors='ignore')
Out[18]: array(['2017-1-1', 'invalid'], dtype=object)

# 将无效数据显示为 NaT
In [19]: pd.to_datetime(['2017-1-1', 'invalid'], errors='coerce')
Out[19]: DatetimeIndex(['2017-01-01', 'NaT'], dtype='datetime64[ns]', freq=None)
接下来，我们看一看生成 DatetimeIndex 的另一个重要方法 pandas.data_range。你应该可以从名字看出该方法的作用，我们可以通过指定一个规则，让 pandas.data_range 生成有序的 DatetimeIndex。

pandas.data_range 方法带有的默认参数如下：

pandas.date_range(start=None, end=None, periods=None, freq=’D’, tz=None, normalize=False,
name=None, closed=None, **kwargs)
常用参数的含义如下：

start= ：设置起始时间
end=：设置截至时间
periods= ：设置时间区间，若 None 则需要设置单独设置起止和截至时间。
freq= ：设置间隔周期。
tz=：设置时区。
其中，freq= 参数是非常关键的参数，我们可以设置的周期有：

freq='s': 秒
freq='min' : 分钟
freq='H': 小时
freq='D': 天
freq='w': 周
freq='m': 月
freq='BM': 每个月最后一天
freq='W'：每周的星期日

# 从 2017-1-1 到 2017-1-2，以小时间隔
In [21]: pd.date_range('2017-1-1','2017-1-2',freq='H')
Out[21]:
DatetimeIndex(['2017-01-01 00:00:00', '2017-01-01 01:00:00',
               '2017-01-01 02:00:00', '2017-01-01 03:00:00',
               '2017-01-01 04:00:00', '2017-01-01 05:00:00',
               '2017-01-01 06:00:00', '2017-01-01 07:00:00',
               '2017-01-01 08:00:00', '2017-01-01 09:00:00',
               '2017-01-01 10:00:00', '2017-01-01 11:00:00',
               '2017-01-01 12:00:00', '2017-01-01 13:00:00',
               '2017-01-01 14:00:00', '2017-01-01 15:00:00',
               '2017-01-01 16:00:00', '2017-01-01 17:00:00',
               '2017-01-01 18:00:00', '2017-01-01 19:00:00',
               '2017-01-01 20:00:00', '2017-01-01 21:00:00',
               '2017-01-01 22:00:00', '2017-01-01 23:00:00',
               '2017-01-02 00:00:00'],
              dtype='datetime64[ns]', freq='H')

# 从 2017-1-1 开始，以 1s 为间隔，向后推 10 次
In [23]: pd.date_range('2017-1-1',periods=10,freq='s')
Out[23]:
DatetimeIndex(['2017-01-01 00:00:00', '2017-01-01 00:00:01',
               '2017-01-01 00:00:02', '2017-01-01 00:00:03',
               '2017-01-01 00:00:04', '2017-01-01 00:00:05',
               '2017-01-01 00:00:06', '2017-01-01 00:00:07',
               '2017-01-01 00:00:08', '2017-01-01 00:00:09'],
              dtype='datetime64[ns]', freq='S')

# 从 2017-1-1 开始，以 1H20min 为间隔，向后推 10 次
In [24]: pd.date_range('1/1/2017', periods=10, freq='1H20min')
Out[24]:
DatetimeIndex(['2017-01-01 00:00:00', '2017-01-01 01:20:00',
               '2017-01-01 02:40:00', '2017-01-01 04:00:00',
               '2017-01-01 05:20:00', '2017-01-01 06:40:00',
               '2017-01-01 08:00:00', '2017-01-01 09:20:00',
               '2017-01-01 10:40:00', '2017-01-01 12:00:00'],
              dtype='datetime64[ns]', freq='80T')
除了生成 DatetimeIndex，我们还可以对已有的 DatetimeIndex 进行操作。这些操作包括选择、切片等。类似于对 Series 的操作。

In [31]: a = pd.date_range('2017-1-1',periods=10,freq='1D1H')

In [32]: a
Out[32]:
DatetimeIndex(['2017-01-01 00:00:00', '2017-01-02 01:00:00',
               '2017-01-03 02:00:00', '2017-01-04 03:00:00',
               '2017-01-05 04:00:00', '2017-01-06 05:00:00',
               '2017-01-07 06:00:00', '2017-01-08 07:00:00',
               '2017-01-09 08:00:00', '2017-01-10 09:00:00'],
              dtype='datetime64[ns]', freq='25H')

# 选取索引为 1 的时间戳
In [33]: a[1]
Out[33]: Timestamp('2017-01-02 01:00:00', freq='25H')

# 对索引从 0 到 4 的时间进行切片
In [34]: a[:5]
Out[34]:
DatetimeIndex(['2017-01-01 00:00:00', '2017-01-02 01:00:00',
               '2017-01-03 02:00:00', '2017-01-04 03:00:00',
               '2017-01-05 04:00:00'],
              dtype='datetime64[ns]', freq='25H')
时间戳和时间戳索引处理操作视频：

Play Video

DateOffset 对象

我们使用 freq='1D1H' 参数，可以生成间隔 1 天+ 1 小时的时间戳索引。而在时序数据处理中，我们还常用一种叫做 DateOffset 对象，它可以对时间戳索引进行更加灵活的变化。DateOffset 对象主要作用有：

1. 可以让时间索引增加或减少一定时间段。

2. 可以让时间索引乘以一个整数。

3. 可以让时间索引向前或向后移动到下一个或上一个特定的偏移日期。

我们依旧针对上面的 a 索引进行处理：

In [1]: import pandas as pd
In [2]: from pandas import offsets

In [3]: a = pd.date_range('2017-1-1',periods=10,freq='1D1H')

In [4]: a
Out[4]:
DatetimeIndex(['2017-01-01 00:00:00', '2017-01-02 01:00:00',
               '2017-01-03 02:00:00', '2017-01-04 03:00:00',
               '2017-01-05 04:00:00', '2017-01-06 05:00:00',
               '2017-01-07 06:00:00', '2017-01-08 07:00:00',
               '2017-01-09 08:00:00', '2017-01-10 09:00:00'],
              dtype='datetime64[ns]', freq='25H')

# 使用 DateOffset 对象让 a 依次增加 1 个月 + 1 天 + 1 小时
In [5]: a + offsets.DateOffset(months=1, days=2, hours=1)
Out[5]:
DatetimeIndex(['2017-02-03 01:00:00', '2017-02-04 02:00:00',
               '2017-02-05 03:00:00', '2017-02-06 04:00:00',
               '2017-02-07 05:00:00', '2017-02-08 06:00:00',
               '2017-02-09 07:00:00', '2017-02-10 08:00:00',
               '2017-02-11 09:00:00', '2017-02-12 10:00:00'],
              dtype='datetime64[ns]', freq='D')

# 使用 DateOffset 对象让 a 向后偏移 2 周

In [6]: a + 2*offsets.Week()
Out[6]:
DatetimeIndex(['2017-01-15 00:00:00', '2017-01-16 01:00:00',
               '2017-01-17 02:00:00', '2017-01-18 03:00:00',
               '2017-01-19 04:00:00', '2017-01-20 05:00:00',
               '2017-01-21 06:00:00', '2017-01-22 07:00:00',
               '2017-01-23 08:00:00', '2017-01-24 09:00:00'],
              dtype='datetime64[ns]', freq='25H')
更多DateOffset 对象列举如下：



DateOffset 对象操作视频：

Play Video

Period 时间间隔

我们对 Timestamp 时间戳和 DatetimeIndex 时间戳索引都有了较为充分的认识。除此之外 Pandas 中还存在 Period 时间间隔和 PeriodIndex 时间间隔索引对象。它们用来定义一定时间跨度。


In [1]: import pandas as pd

# 1 年跨度
In [2]: pd.Period('2017')
Out[2]: Period('2017', 'A-DEC')

# 1 个月跨度
In [3]: pd.Period('2017-1')
Out[3]: Period('2017-01', 'M')

# 1 天跨度
In [4]: pd.Period('2017-1-1')
Out[4]: Period('2017-01-01', 'D')

# 1 小时跨度
In [8]: pd.Period('2017-1-1 12')
Out[8]: Period('2017-01-01 12:00', 'H')

# 1 分钟跨度
In [5]: pd.Period('2017-1-1 12:00')
Out[5]: Period('2017-01-01 12:00', 'T')

# 1 秒跨度
In [6]: pd.Period('2017-1-1 12:05:00')
Out[6]: Period('2017-01-01 12:05:00', 'S')
同样我们可以通过 pandas.period_range() 方法来生成序列：


In [9]: pd.period_range('2017-1','2018-1',freq='M')
Out[9]:
PeriodIndex(['2017-01', '2017-02', '2017-03', '2017-04', '2017-05', '2017-06',
             '2017-07', '2017-08', '2017-09', '2017-10', '2017-11', '2017-12',
             '2018-01'],
            dtype='period[M]', freq='M')
Period，PeriodIndex支持的操作和Timestamp以及DatetimeIndex 非常相似，这里就不再重复赘述了。

我们可以注意几个细节，DatetimeIndex 的dtype 类型为 datetime64[ns]，而 PeriodIndex 的 dtype 类型为 period[M]。另外，对于 Timestamp和 Period 的区别，我们在单独拿出来看一下：

In [15]: pd.Period('2017-1-1')
Out[15]: Period('2017-01-01', 'D')

In [16]: pd.Timestamp('2017-1-1')
Out[16]: Timestamp('2017-01-01 00:00:00')
可以看到，上面代表是2017-01-01这一天，而下面仅代表 2017-01-01 00:00:00 这一时刻。

Period 时间间隔操作视频：

Play Video

时序数据检索

DatetimeIndex 之所以称之为时间戳索引，当然是它的主要用途是作为 Series 或者 DataFrame 的索引。下面，我们就随机生成一些数据，然后看一看如果对时间序列数据进行操作。


In [1]: import numpy as np

In [2]: import pandas as pd

# 生成时间索引
In [3]: i = pd.date_range('2017-1-1', periods=20, freq='M')

# 生成随机数据并添加时间作为索引
In [4]: data = pd.Series(np.random.randn(len(i)), index = i)

# 查看数据
In [5]: data
Out[5]:
2017-01-31   -1.233579
2017-02-28    0.494723
2017-03-31   -2.160592
2017-04-30    0.517173
2017-05-31   -1.984762
2017-06-30    0.655989
2017-07-31    0.919411
2017-08-31    0.114805
2017-09-30   -0.080374
2017-10-31    1.360448
2017-11-30   -0.417094
2017-12-31    0.555434
2018-01-31    1.659271
2018-02-28   -0.514907
2018-03-31    0.330979
2018-04-30   -0.707362
2018-05-31   -0.724524
2018-06-30    0.362518
2018-07-31    0.157280
2018-08-31   -0.724665
Freq: M, dtype: float64
上面就生成了一个以时间为索引的 Series 序列。其实，这就回到了对 Pandas 中 Series 和 DataFrame 类型数据操作的问题。下面演示一些操作：

# 检索 2017 年的所有数据
In [12]: data['2017']
Out[12]:
2017-01-31   -1.233579
2017-02-28    0.494723
2017-03-31   -2.160592
2017-04-30    0.517173
2017-05-31   -1.984762
2017-06-30    0.655989
2017-07-31    0.919411
2017-08-31    0.114805
2017-09-30   -0.080374
2017-10-31    1.360448
2017-11-30   -0.417094
2017-12-31    0.555434
Freq: M, dtype: float64

# 检索 2017 年 7 月到 2018 年 3 月之间的所有数据
In [13]: data['2017-07':'2018-03']
Out[13]:
2017-07-31    0.919411
2017-08-31    0.114805
2017-09-30   -0.080374
2017-10-31    1.360448
2017-11-30   -0.417094
2017-12-31    0.555434
2018-01-31    1.659271
2018-02-28   -0.514907
2018-03-31    0.330979
Freq: M, dtype: float64

# 使用 loc 方法检索 2017 年 1 月的所有数据
In [14]: data.loc['2017-01']
Out[14]:
2017-01-31   -1.233579
Freq: M, dtype: float64

# 使用 truncate 方法检索 2017-3-1 到 2018-4-2 期间的数据
In [17]: data.truncate(before='2017-3-1',after='2018-4-2')
Out[17]:
2017-03-31   -2.160592
2017-04-30    0.517173
2017-05-31   -1.984762
2017-06-30    0.655989
2017-07-31    0.919411
2017-08-31    0.114805
2017-09-30   -0.080374
2017-10-31    1.360448
2017-11-30   -0.417094
2017-12-31    0.555434
2018-01-31    1.659271
2018-02-28   -0.514907
2018-03-31    0.330979
Freq: M, dtype: float64
时序数据检索操作视频：

Play Video

时序数据偏移

对于时序数据的处理，肯定不只是查询和切片这么简单。我们这里可能会用到 Shifting 方法，将时间索引进行整体偏移。


In [1]: import numpy as np

In [2]: import pandas as pd

# 生成时间索引
In [3]: i = pd.date_range('2017-1-1', periods=5, freq='M')

# 生成随机数据并添加时间作为索引
In [4]: data = pd.Series(np.random.randn(len(i)), index = i)

# 查看数据
In [5]: data
Out[5]:
2017-01-31    0.830480
2017-02-28    0.348324
2017-03-31   -0.622078
2017-04-30   -1.192675
2017-05-31    0.441947
Freq: M, dtype: float64

# 将索引向前位移 3 个单位，也就是数据向后位移 3 个单位，缺失数据 Pandas 会用 NaN 自动填充
In [8]: data.shift(3)
Out[8]:
2017-01-31         NaN
2017-02-28         NaN
2017-03-31         NaN
2017-04-30    0.830480
2017-05-31    0.348324
Freq: M, dtype: float64

# 将索引向后位移 3 个单位，也就是数据向前位移 3 个单位
In [9]: data.shift(-3)
Out[9]:
2017-01-31   -1.192675
2017-02-28    0.441947
2017-03-31         NaN
2017-04-30         NaN
2017-05-31         NaN
Freq: M, dtype: float64

# 将索引的时间向后移动 3 天
In [10]: data.shift(3,freq='D')
Out[10]:
2017-02-03    0.830480
2017-03-03    0.348324
2017-04-03   -0.622078
2017-05-03   -1.192675
2017-06-03    0.441947
dtype: float64
时序数据偏移操作视频：

Play Video

时序数据重采样

除了 Shifting 方法，重采样 Resample 也会经常用到。Resample 可以提升或降低一个时间索引序列的频率，大有用处。例如：当时间序列数据量非常大时，我们可以通过低频率采样的方法得到规模较小到时间覆盖依然较为全面的新数据集。另外，对于多个不同频率的数据集需要数据对齐时，重采样可以十分重要的手段。

In [1]: import pandas as pd

In [2]: import numpy as np

In [3]: i = pd.date_range('2017-1-1', periods=20, freq='D')

In [4]: data = pd.Series(np.random.randn(len(i)), index = i)

In [5]: data
Out[5]:
2017-01-01    0.384984
2017-01-02    0.341555
2017-01-03   -0.100246
2017-01-04   -0.660066
2017-01-05    0.007575
2017-01-06    2.402068
2017-01-07   -0.365657
2017-01-08   -0.853025
2017-01-09    0.588139
2017-01-10    0.047322
2017-01-11    0.213384
2017-01-12    1.056038
2017-01-13   -1.588518
2017-01-14    0.076655
2017-01-15    1.467056
2017-01-16   -1.877541
2017-01-17    0.003218
2017-01-18   -0.811914
2017-01-19    0.143571
2017-01-20    0.837088
Freq: D, dtype: float64

# 按照 2 天进行降采样，并对 2 天对应的数据求和作为新数据
In [6]: data.resample('2D').sum()
Out[6]:
2017-01-01    0.726539
2017-01-03   -0.760312
2017-01-05    2.409643
2017-01-07   -1.218682
2017-01-09    0.635461
2017-01-11    1.269422
2017-01-13   -1.511864
2017-01-15   -0.410485
2017-01-17   -0.808696
2017-01-19    0.980658
Freq: 2D, dtype: float64

# 按照 2 天进行降采样，并对 2 天对应的数据求平均值作为新数据
In [7]: data.resample('2D').mean()
Out[7]:
2017-01-01    0.363269
2017-01-03   -0.380156
2017-01-05    1.204821
2017-01-07   -0.609341
2017-01-09    0.317730
2017-01-11    0.634711
2017-01-13   -0.755932
2017-01-15   -0.205243
2017-01-17   -0.404348
2017-01-19    0.490329
Freq: 2D, dtype: float64

# 按照 2 天进行降采样，并选取对应 2 天的最大值作为新数据
In [9]: data.resample('2D').max()
Out[9]:
2017-01-01    0.384984
2017-01-03   -0.100246
2017-01-05    2.402068
2017-01-07   -0.365657
2017-01-09    0.588139
2017-01-11    1.056038
2017-01-13    0.076655
2017-01-15    1.467056
2017-01-17    0.003218
2017-01-19    0.837088
Freq: 2D, dtype: float64

# 按照 2 天进行降采样，并将对应 2 天数据的原值、最大值、最小值、以及临近值列出
In [10]: data.resample('2D').ohlc()
Out[10]:
                open      high       low     close
2017-01-01  0.384984  0.384984  0.341555  0.341555
2017-01-03 -0.100246 -0.100246 -0.660066 -0.660066
2017-01-05  0.007575  2.402068  0.007575  2.402068
2017-01-07 -0.365657 -0.365657 -0.853025 -0.853025
2017-01-09  0.588139  0.588139  0.047322  0.047322
2017-01-11  0.213384  1.056038  0.213384  1.056038
2017-01-13 -1.588518  0.076655 -1.588518  0.076655
2017-01-15  1.467056  1.467056 -1.877541 -1.877541
2017-01-17  0.003218  0.003218 -0.811914 -0.811914
2017-01-19  0.143571  0.837088  0.143571  0.837088
采样操作起来非常简单，只是需要注意采样后对新数据不同的处理方法。上面介绍的是降频采样。我们也可以升频采样。

继续沿用上面 data 的示例数据

# 时间频率从天提升到小时，并使用相同的数据对新增加行填充
In [11]: data.resample('H').ffill()
Out[11]:
2017-01-01 00:00:00    0.384984
2017-01-01 01:00:00    0.384984
2017-01-01 02:00:00    0.384984
2017-01-01 03:00:00    0.384984
2017-01-01 04:00:00    0.384984

                         ...

2017-01-19 21:00:00    0.143571
2017-01-19 22:00:00    0.143571
2017-01-19 23:00:00    0.143571
2017-01-20 00:00:00    0.837088
Freq: H, Length: 457, dtype: float64


# 时间频率从天提升到小时，不对新增加行填充
In [12]: data.resample('H').asfreq()
Out[12]:
2017-01-01 00:00:00    0.384984
2017-01-01 01:00:00         NaN
2017-01-01 02:00:00         NaN

                         ...

2017-01-19 23:00:00         NaN
2017-01-20 00:00:00    0.837088
Freq: H, Length: 457, dtype: float64

# 时间频率从天提升到小时，只对新增加前 3 行填充
In [13]: data.resample('H').ffill(limit=3)
Out[13]:
2017-01-01 00:00:00    0.384984
2017-01-01 01:00:00    0.384984
2017-01-01 02:00:00    0.384984
2017-01-01 03:00:00    0.384984
2017-01-01 04:00:00         NaN
2017-01-01 05:00:00         NaN

                         ...

2017-01-19 21:00:00         NaN
2017-01-19 22:00:00         NaN
2017-01-19 23:00:00         NaN
2017-01-20 00:00:00    0.837088
Freq: H, Length: 457, dtype: float64
时序数据重采样操作视频：

Play Video

实验总结

本章节学习了 Pandas 针对时间序列分析处理的一些方法。我们用到的类和方法虽然不多，但使用起来非常灵活多变。很多时候，我们需要的结果存在多种不同的实现途径，所以这些方法看起比较杂乱。而学习时，一定要对照本章一开始给出的图表进行，就能达到事半功倍的效果。

Python 数据分析入门四实验楼课程数据分析
内容简介

本实验主要使用实验楼课程数据来进行一次实战性质的时间序列分析。由于我们自己爬取到的课程数据类型有限，所以这里分用到的课程数据是实验楼内部导出来的数据。

知识点

实验楼课程数据读取
时序数据分析
课程学习时间变化趋势分析
实验楼实验学习情况分析
数据概览

本次课程的数据来源于实验楼运行过程中产生的真实数据，我们对部分数据进行了脱敏处理。

首先，我们需要下载课程数据集 courses.txt。

wget http://labfile.oss.aliyuncs.com/courses/764/courses.txt
下载之后，可以通过 head 命令预览数据文件的前 10 行。

head -10 courses.txt


预览数据集，能让我们对数据结构，包含的大致内容有快速了解。这里，通过预览courses.txt，我们可以得到以下几条结论：

是典型的通过逗号分割的文本数据集。
数据集大致分为 4 列，且已经包含列名。
数据集第 1 列为时间序列。
数据集第 2 列为字符串类型。
数据集第 3，4 列为数值类型。
总之，我们可以发现该数据集并不是特别复杂。

实验楼课程时序数据查看视频：

Play Video

读取数据

了解数据集的类型之后，我们就可以开始读取数据，并对数据进行简单处理。当然，这里肯定会用到的就是 Pandas 数据处理开源工具了。

我们依旧通过实验楼线上提供的ipython终端来执行代码，线下练习推荐使用 Jupyter Notebook。

$ anaconda3/bin/ipython
进入 ipython 后，开始导入数据文件：


In [1]: import pandas as pd

# 导入文本文件，使用逗号分割
In [2]: courses_ori = pd.read_table('courses.txt', sep=',', header=0)

# 预览 DataFrame 前 5 行
In [3]: courses_ori.head()
Out[3]:
              创建时间            课程名称    学习人数      学习时间
0  2013/5/13 10:55  Linux 基础入门（新版）  391962  23875374
1  2013/5/13 10:58          Vim编辑器  118629   2590047
2  2013/5/13 10:58      Python编程语言   51879   1189731
3  2013/5/13 10:59        Git 实战教程   93153   2109564
4  2013/5/13 11:06      MySQL 基础课程   78792   4229313
实验楼课程时序数据读取视频：

Play Video

课程学习时间变化趋势

既然数据集中包含有时间，那么我们就可以做一个简单的时间序列分析，看一看课程学习人数和学习时间的随着时间的变化情况。

第一步当然是将时间数据变为 DatetimeIndex 格式，这样时间就可以作为索引了。

In [4]: i = pd.to_datetime(courses_ori['创建时间'])

In [5]: i.head()
Out[5]:
0   2013-05-13 10:55:00
1   2013-05-13 10:58:00
2   2013-05-13 10:58:00
3   2013-05-13 10:59:00
4   2013-05-13 11:06:00
Name: 创建时间, dtype: datetime64[ns]
然后，我们对原始数据courses_ori进行修改。


In [9]: courses_ts = pd.DataFrame(data=courses_ori.values, columns=courses_ori.columns, index=i)

In [10]: courses_ts.head()
Out[10]:
                                创建时间            课程名称    学习人数      学习时间
创建时间
2013-05-13 10:55:00  2013/5/13 10:55  Linux 基础入门（新版）  391962  23875374
2013-05-13 10:58:00  2013/5/13 10:58          Vim编辑器  118629   2590047
2013-05-13 10:58:00  2013/5/13 10:58      Python编程语言   51879   1189731
2013-05-13 10:59:00  2013/5/13 10:59        Git 实战教程   93153   2109564
2013-05-13 11:06:00  2013/5/13 11:06      MySQL 基础课程   78792   4229313
此时，我们成功将原创建时间修改为了 courses_ts 的时间戳索引。但是，原来的 创建时间 列依旧存在，需要将其去除。

In [11]: courses_ts = courses_ts.drop("创建时间", axis=1)

In [12]: courses_ts.head()
Out[12]:
                               课程名称    学习人数      学习时间
创建时间
2013-05-13 10:55:00  Linux 基础入门（新版）  391962  23875374
2013-05-13 10:58:00          Vim编辑器  118629   2590047
2013-05-13 10:58:00      Python编程语言   51879   1189731
2013-05-13 10:59:00        Git 实战教程   93153   2109564
2013-05-13 11:06:00      MySQL 基础课程   78792   4229313
接下来，我们先看一看学习人数和学习时间随着时间变化的趋势。为了更方便绘图，我们可以进一步减少数据量，这里可以用 Pandas 对时间序列降采样。

这里，我们按照周次频率进行降采样。

# 按照周次频率进行降采样
In [13]: courses_ts_W = courses_ts.resample('W').sum()
然后，我们使用 Matplotlib 对学习人数和学习时间随着时间变化的趋势进行绘图。

这里拿累计学习时间举例，尝试绘制折线图

In [14]: import matplotlib.pyplot as plt

In [15]: plt.plot_date(courses_ts_W.index, courses_ts_W['学习时间'], '-')
In [16]: plt.xlabel('Time Series')
In [17]: plt.ylabel("Study Time")
In [18]: plt.show()


采用常用的plt.plot()或者 plt.plot_date() 绘制出的这张图看起来很糟糕，它似乎并不能很好地传达出实验课程累计学习时间的变化趋势。

这里，我们学习引入另一个绘图库 Seaborn，它是整合了 Matplotlib 核心方法的高级绘图库，

我们使用Seaborn 提供的 regplot 方法，它可以在绘制散点图时，对数据自动进行回归拟合。我们一起来看一下：

# 使用 Seaborn 时，须同时引入 Matplotlib
In [19]: import matplotlib.pyplot as plt
In [20]: import seaborn as sns

# 新添加一个序数列，方便绘制散点图
In [21]: courses_ts_W['id'] = range(0,len(courses_ts_W.index.values))

In [22]: sns.regplot("id", "学习时间", data=courses_ts_W, scatter_kws={"s": 10}, order=8, ci=None, truncate=True)

In [23]: plt.xlabel('Time Series')
In [24]: plt.ylabel("Study Time")
In [25]: plt.show()
看起来比上面直接绘制折线图要好很多。但是，这条显示趋势的拟合线似乎依旧有一些问题。



一开始数据向下凹的厉害，以及最后的翘尾。重新查看数据，我们可以发现曲线下凹部分是由于实验楼在 2013 年的第二、第三季度新增课程较少。而尾部的上翘，应归结于拟合偏差，你可以通过减小 order=参数的数值，来降低这种偏差。

当然，我们还可以通过设置 x_bins= 参数，绘制出能更加直观反映上升或下降趋势的图像。

In [26]: sns.regplot("id", "学习人数", data=courses_ts_W, x_bins=10)

In [27]: plt.xlabel('Time Series')
In [28]: plt.ylabel("Students")
In [29]: plt.show()
我们进一步降低了采样点，并得到了置信区间。这就能很清晰地反映出，课程累计实验时长随着创建时间的推移在逐渐减少。



你可能会纳闷，课程累计实验时长为什么会逐渐减少？原因当然很简单，新课程出来之后，一开始学习的人数较少，累计学习的时间也比较少。而老课程时间的增加，尤其是很多年前的课程累计实验时间数值非常高。这也反映了，实验楼的课程质量经得住时间考验。

实验楼课程学习时间变化趋势分析视频：

Play Video

实验学习情况分析

既然我们有每门课程的总学习时间和学习人数，那么我们就能计算出每门课下，每个人的平均学习时间。

# 每次做单独分析时，最好复制一份整理好的数据，减少对原数据集影响
In [30]: courses_ts_A = courses_ts.copy()

# 计算平均学习时间并添加列
In [31]: courses_ts_A['平均学习时间'] = courses_ts_A['学习时间']/courses_ts_A['学习人数']

# 预览
In [32]: courses_ts_A.head()
Out[32]:
创建时间        课程名称         学习人数      学习时间   平均学习时间
2013-05-13 10:55:00  Linux 基础入门（新版）  391962  23875374  60.9125
2013-05-13 10:58:00          Vim编辑器  118629   2590047  21.8332
2013-05-13 10:58:00      Python编程语言   51879   1189731  22.9328
2013-05-13 10:59:00        Git 实战教程   93153   2109564  22.6462
2013-05-13 11:06:00      MySQL 基础课程   78792   4229313  53.6769
我们可以依据平均时间对数据集进行排序，然后预览前 5 条和后 5 条数据：

In [33]: courses_ts_A.sort_values(by='平均学习时间', ascending=False).head()


看以看出，平均学习时间较长的都是训练营课程，这也预料之中。因为训练营课程内容较多，所以平均学习时间自然较长。

查看后 5 条数据如下：

In [34]: courses_ts_A.sort_values(by='平均学习时间', ascending=False).tail()


对于平均学习时间较短的这些数据。我们可以发现这些课程的共同特点，那就是可能没有添加在线实验环境，或者是在本地书写代码，在线提交结果的任务型课程。

如果我们进一步分析课程的异常情况，可以查看一些学习人数偏多，但平均时间明显偏少的课程。这里，需要计算学习人数与平均学习时间的比值：

# 添加新列
# 注意平均学习时间有可能有0值，所以需要修改0值为0.01
# 修改方法可以使用 loc 方法制定索引及列名获取元素，然后赋值为 0.01
In [35]: courses_ts_A['人数/平均学习时间'] = courses_ts_A['学习人数']/courses_ts_A['平均学习时间']



# 按照比值从小到大排序并显示后 10 条
In [36]: courses_ts_A.sort_values(by='人数/平均学习时间').tail(10)
下图显示的是学习人数与平均学习时间比值最为悬殊的前 10 条数据。



排除第一条异常数据，以及第二条不需要太多操作的课程，我们可以发现剩下的课程大多都提供了线上环境。这些课程学习人数众多，但是平均学习时间少的可怜。对于这样的现状大致存在三种原因：

实验有趣，但难度大、代码多。所以，很多用户快速地完成了从开机到放弃的过程。
部分用户可能直接下载提供的完成代码文件，识别了一下色情图片或 2048 游戏，并未逐一手写代码实现。
部分用户可能选择在本地 IDE 测试，没有被统计到时间。
实验楼后续可能会针对这些选题有趣的实验进行优化，避免大家只是玩玩而并未真正地去手动实现。

另外，通过绘制出平均学习时间和学习人数的关系图，我们可以更直观地看出需要重点关注的课程。

In [37]: sns.jointplot("平均学习时间", "学习人数", kind='scatter', data=courses_ts_A)

In [23]: plt.xlabel('Average Study Time')
In [24]: plt.ylabel("Number of Users")
In [38]: plt.show()
对于靠近坐标轴的数据，都是我们需要重点关注的课程。



实验楼实验学习情况分析视频：

Play Video

进一步学习

楼+课程中数据分析部分的时间只有一周，只是简单入门学习了 Numpy、Pandas、Matplotlib 等基础库，没有涉及到数据分析中大量的机器学习算法。由于每位楼+的用户都是会员，所以推荐大家如果对数据分析感兴趣，可以深入学习实验楼的大量数据分析的会员课程，但前提仍然是需要先把熟悉楼+四个实验，这样才能够事半功倍。

推荐可以从这三门课程入手：

Matplotlib 及 Seaborn 使用教程
scikit-learn 实战之非监督学习
scikit-learn 实战之监督学习

